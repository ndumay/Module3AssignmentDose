# Trying my best a learn how to use GitHub and Jupyter Notebooks. 
# Read that an appendix should be created for use of ChatGPT or other AI Assistance.
# I want to make sure that I am following the rules. Please advise if I should be doing anything differently.


# BU AI Use Policy: https://www.bu.edu/cds-faculty/culture-community/gaia-policy/
# BU APA Formatted AI Use Citation: "OpenAI. (2024). Transcript of conversation with problem-solving solutions. Unpublished interaction transcript. Retrieved from OpenAI’s ChatGPT platform. In accordance with Boston University GAIA policy."


# BU AI Use Citation Requirements:
# b) ChatGPT (Subscription) 
# c) Primarily will be using ChatGPT to prime myself for how to solution for problems within an assignment, what libraries most help with solving the problem, and then walking me through the steps to understanding how to get to the solution. ChatGPT, is helping me bridge a gap in my understand of converting course concepts to code;
# d) AI is primarily being used as a preceptor that translates teachings information into to practical development knowledge to better understand the steps to the solution, learn optimal development to a given problem to form wisdom;

# Initial Dialog: 
# Asked for help with a homework assignment using GitHub Codespaces, Python, and Jupyter Notebooks. 
# Provided libraries to be used and mentioned that I would need to cite the use of ChatGPT in the appendix.
# Requested help in solving problems seaking step by step instructional breakdown for learning for 10 questions.


# a) the entire exchange, highlighting the most relevant sections;

# Problem Statements and Solution Steps Summary with Detailed Explanations

# Summary:
# **Jupyter Notebook Transcript - Full Conversation**

# ---
# **Section 1: Generating and Visualizing a Regression Dataset**
# **Question:**
# How do I generate and visualize a simple univariate regression dataset using `make_regression`?
#
# **Subject:**
# Creating a synthetic dataset using `sklearn.datasets.make_regression`
#
# **Answer:**
# You can use `make_regression` to generate a dataset with a specified number of samples,
# noise level, and bias. Visualization helps in understanding the distribution.
#
# **Code Example:**
# import numpy as np
# import matplotlib.pyplot as plt
# from sklearn.datasets import make_regression
#
# # Set parameters
# X, y, coef = make_regression(n_samples=20, n_features=1, noise=20, bias=0.5, random_state=42, coef=True)
#
# # Plot scatterplot
# plt.scatter(X, y, color="blue")
# plt.xlabel("Feature (X)")
# plt.ylabel("Target (y)")
# plt.title("Generated Regression Dataset")
# plt.show()

# **Follow-up:**
# User asked about computing the underlying model without noise.
#
# **Answer:**
# - The underlying model is the true regression function before noise is added.
# - `make_regression()` generates `y` values with random fluctuations (`noise=20`).
# - The true model can be computed as:
#
# y_model = X_sorted * coef + bias
#
# - Visualization should include both the **true model (without noise)** and the **data points (with noise)**.

# ---
# **Section 2: Training and Evaluating a Linear Regression Model**
# **Question:**
# How do I train a linear regression model using `sklearn.linear_model.LinearRegression`?
#
# **Subject:**
# Implementing linear regression and extracting key metrics
#
# **Answer:**
# You can fit a linear regression model using `LinearRegression.fit()`, extract the slope and intercept,
# and compute performance metrics such as Mean Squared Error (MSE).
#
# **Code Example:**
# from sklearn.linear_model import LinearRegression
# model = LinearRegression()
# model.fit(X, y)
# slope = model.coef_[0]
# intercept = model.intercept_
# print(f"Slope: {slope}, Intercept: {intercept}")

# **Follow-up:**
# User asked how to compute and round the training MSE.
#
# **Answer:**
# Use `mean_squared_error()` to compute MSE and round it to four decimal places.
#
# **Code Example:**
# from sklearn.metrics import mean_squared_error
# y_pred = model.predict(X)
# training_mse = np.around(mean_squared_error(y, y_pred), decimals=4)
# print(f"Training MSE: {training_mse}")

# ---
# **Section 3: Generating and Evaluating New Test Samples**
# **Question:**
# How do I generate new test samples from the same distribution as the training data?
#
# **Subject:**
# Creating additional test samples following the original distribution
#
# **Answer:**
# - Sample new `X` values from the **same range** as `X` using `np.random.uniform()`.
# - Compute `y` using the **true underlying regression equation** (without noise).
#
# **Code Example:**
# def generate_sample():
#     x_new = np.random.uniform(X.min(), X.max())
#     y_new = coef * x_new + bias  # No noise added
#     return (x_new, y_new)

# **Follow-up:**
# User asked why noise isn't included in the new test samples.
#
# **Answer:**
# - Since we are testing model generalization, we use **clean data** (without noise).
# - The original dataset included noise (`noise=20`), but test samples should follow the **true function**.
# - Adding noise to new samples would make them inconsistent with the fitted regression line.

# ---
# **Section 4: Multiple Regression and Feature Correlations**
# **Question:**
# How do I analyze feature correlations in the Diabetes dataset?
#
# **Subject:**
# Using `corr()` and `seaborn.heatmap()` to visualize correlations
#
# **Answer:**
# Compute the correlation matrix and plot it using Seaborn to understand feature relationships.
#
# **Code Example:**
# import seaborn as sns
# import matplotlib.pyplot as plt
#
# correlation_matrix = df_diabetes.corr()
# plt.figure(figsize=(10,8))
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
# plt.title("Feature Correlation Matrix - Diabetes Dataset")
# plt.show()

# **Follow-up:**
# User asked how to identify the most correlated feature.
#
# **Answer:**
# - The highest correlation to `DiseaseProgression` can be found using:
#
# correlations = correlation_matrix["DiseaseProgression"].drop("DiseaseProgression")
# most_correlated_feature = correlations.abs().idxmax()
#
# - In this dataset, **BMI (`bmi`)** is the most correlated feature.

# ---
# **Section 5: Univariate vs. Multiple Regression**
# **Question:**
# How do I compare a univariate regression model (bmi) with a multiple regression model?
#
# **Subject:**
# Training two models and comparing their Mean Squared Error (MSE)
#
# **Answer:**
# First, train a **univariate** regression model using only `bmi`.
#
# **Code Example:**
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression
# from sklearn.metrics import mean_squared_error
#
# X_uni = X[['bmi']]
# X_train, X_test, y_train, y_test = train_test_split(X_uni, y, test_size=0.2, random_state=42)
#
# model_uni = LinearRegression()
# model_uni.fit(X_train, y_train)
# y_pred_train = model_uni.predict(X_train)
# mse_uni = np.around(mean_squared_error(y_train, y_pred_train), decimals=4)
# print(f"Training MSE (Univariate - bmi): {mse_uni}")

# Then, train a **multiple regression model** using all features.
#
# **Code Example:**
# model_multi = LinearRegression()
# model_multi.fit(X, y)
# y_pred_multi = model_multi.predict(X)
# mse_multi = np.around(mean_squared_error(y, y_pred_multi), decimals=4)
# print(f"Training MSE (Multiple Regression): {mse_multi}")

# **Follow-up:**
# User asked how training size affects MSE.
#
# **Answer:**
# - **Larger training sets improve generalization** → Testing MSE tends to decrease.
# - **Training MSE may slightly increase** because the model sees more variance in the data.
# - **Conceptual takeaway:** A model trained on **more data** is usually better at making accurate predictions on unseen data.

# ---
# **Section 6: Evaluating Model Generalization**
# **Question:**
# How do I evaluate a regression model’s performance on test data?
#
# **Subject:**
# Using `train_test_split` to compare training vs. testing performance
#
# **Answer:**
# Split the data and compare the **train MSE** and **test MSE**.
#
# **Code Example:**
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# model = LinearRegression()
# model.fit(X_train, y_train)
# y_train_pred = model.predict(X_train)
# y_test_pred = model.predict(X_test)
#
# mse_train = np.around(mean_squared_error(y_train, y_train_pred), decimals=4)
# mse_test = np.around(mean_squared_error(y_test, y_test_pred), decimals=4)
# print(f"Training MSE: {mse_train}, Testing MSE: {mse_test}")

# **Follow-up:**
# User asked why training MSE is sometimes larger than test MSE.
#
# **Answer:**
# - Small datasets may have **outliers** that inflate training error.
# - If the test set is small, **random selection** could make it easier to predict.

# ---
# **End of Transcript**